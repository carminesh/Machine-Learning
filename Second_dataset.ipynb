{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary libraries & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the libraries are imported correctly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from load_data import load_data\n",
    "\n",
    "\n",
    "print('All the libraries are imported correctly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess all the data from the first dataset and then split it into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dataset2.csv\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data('data/dataset2.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Data standardization\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and fit the data to the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier()  \n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_forest_pred = random_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and fit the data to the K-N Neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_neighbors_model = KNeighborsClassifier(n_neighbors=19)   \n",
    "kn_neighbors_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_knn_pred = kn_neighbors_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Grid Search in order to find the best hyper-parameter for the K-N Neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/carminefa/UniversitaÌ€/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb Cella 10\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grid_search_classification \u001b[39m=\u001b[39m GridSearchCV(kn_neighbors_model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                            {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mn_neighbors\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                             },cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m#use all processors\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Find out the best parameters for the classifier\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest classification hyper-parameters: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39mgrid_search_classification\u001b[39m.\u001b[39;49mbest_params_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carminefa/Universita%CC%80/Sapienza/Progetti/Machine-Learning/Second_dataset.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest accuracy: \u001b[39m\u001b[39m%.1f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39mgrid_search_classification\u001b[39m.\u001b[39mbest_score_)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "grid_search_classification = GridSearchCV(kn_neighbors_model,\n",
    "                           {\n",
    "                                'n_neighbors': np.arange(1, 21)\n",
    "                            },cv=5, scoring=\"accuracy\",verbose=1,n_jobs=-1 #use all processors\n",
    ")\n",
    "\n",
    "grid_search_classification.fit(X,Y)\n",
    "\n",
    "# Find out the best parameters for the classifier\n",
    "print(\"Best classification hyper-parameters: %r\" %grid_search_classification.best_params_)\n",
    "print(\"Best accuracy: %.1f\" %grid_search_classification.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and fit the data to the SVM model with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_kernel_model = SVC(kernel='rbf', C=1)  \n",
    "svm_rbf_kernel_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_rbf_pred = svm_rbf_kernel_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the accuracy of the model by using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model_scores = cross_val_score(random_forest_model, X, Y, cv=5, scoring='accuracy')\n",
    "kn_neighbors_model_scores = cross_val_score(kn_neighbors_model, X, Y, cv=5, scoring='accuracy')\n",
    "svm_rbf_kernel_model_scores = cross_val_score(svm_rbf_kernel_model, X, Y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"Random Forest Model Cross-Validation Scores:\", random_forest_model_scores)\n",
    "print(\"K Neighbors Model Cross-Validation Scores:\", kn_neighbors_model_scores)\n",
    "print(\"Rbf kernel Cross-Validation Scores:\", svm_rbf_kernel_model_scores)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Calculate and print the mean and standard deviation of the scores\n",
    "print(\"Random Forest Model Standard Deviation:\", random_forest_model_scores.std(), \" vs. K Neighbors Model Standard Deviation:\", kn_neighbors_model_scores.std() ,\" vs. Rbf kernel Standard Deviation: \", svm_rbf_kernel_model_scores.std())\n",
    "print(\"Random Forest Model Mean Accuracy: \", random_forest_model_scores.mean(), \" vs. K Neighbors Model Mean Accuracy:\", kn_neighbors_model_scores.mean(), \" vs. Rbf kernel Mean Accuracy: \", svm_rbf_kernel_model_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_accuracy = accuracy_score(y_test, y_forest_pred)\n",
    "random_forest_recall =  recall_score(y_test, y_forest_pred, average='micro')\n",
    "random_forest_precision =  precision_score(y_test, y_forest_pred, average='micro')\n",
    "random_forest_report = classification_report(y_test, y_forest_pred)\n",
    "\n",
    "kn_neighbors_accuracy = accuracy_score(y_test, y_knn_pred)\n",
    "kn_neighbors_recall = recall_score(y_test, y_knn_pred, average='micro')\n",
    "kn_neighbors_precision = precision_score(y_test, y_knn_pred, average='micro')\n",
    "kn_neighbors_report = classification_report(y_test, y_knn_pred)\n",
    "\n",
    "rbf_k_accuracy = accuracy_score(y_test, y_rbf_pred)\n",
    "rbf_k_recall = recall_score(y_test, y_rbf_pred, average='micro')\n",
    "rbf_k_precision = precision_score(y_test, y_rbf_pred, average='micro')\n",
    "rbf_k_report = classification_report(y_test, y_rbf_pred)\n",
    "\n",
    "print(\"Random Forest Model Accuracy:\", random_forest_accuracy, \" vs. K Neighbors Model Accuracy: \", kn_neighbors_accuracy, \" vs. Rbf Kernel Accuracy: \", rbf_k_accuracy)\n",
    "print(\"Random Forest Model Recall:\", random_forest_recall, \" vs. K Neighbors Model Recall: \", kn_neighbors_recall, \" vs. Rbf Kernel Recall: \", rbf_k_recall)\n",
    "print(\"Random Forest Model Precision:\", random_forest_precision, \" vs. K Neighbors Model Precision: \", kn_neighbors_precision, \" vs. Rbf Kernel Precision: \", rbf_k_precision)\n",
    "\n",
    "# Report section\n",
    "print(\"Random Forest Model Classification Report:\\n\", random_forest_report)\n",
    "print(\"K Neighbors Model Classification Report:\\n\", kn_neighbors_report)\n",
    "print(\"Rbf Kernel Classification Report:\\n\", rbf_k_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the performance of the model by using a confusion matrix - SVM w. RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_rbf_pred) \n",
    "\n",
    "# Display the confusion matrix using a heatmap for better visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix - SVM with RBF kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the 'blind test dataset' on the trained SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_test_data, y = load_data('data/blind_test2.csv')\n",
    "\n",
    "# Standardize the feature data for the blind test dataset\n",
    "X_blind = scaler.transform(blind_test_data)\n",
    "\n",
    "# Make predictions on the blind test data\n",
    "blind_test_predictions = svm_rbf_kernel_model.predict(X_blind)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(blind_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions for data in the 'blind tests' into a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the blind predictions to a file \n",
    "#df['X'] = df.apply(lambda row: row.values, axis=1)\n",
    "df['Predicted_label_class'] = blind_test_predictions\n",
    "\n",
    "# Remove all the columns from the dataframe except the last one: the last one is the Y column with the predictions.\n",
    "df = df.iloc[:, -1:]\n",
    "\n",
    "# Export predictions for data into a .csv file\n",
    "df.to_csv('d2_2133421.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
